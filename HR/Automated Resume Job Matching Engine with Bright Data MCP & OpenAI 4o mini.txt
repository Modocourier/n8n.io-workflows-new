================================================================================
WORKFLOW: Automated Resume Job Matching Engine with Bright Data MCP & OpenAI 4o mini
================================================================================

üìã BASIC INFORMATION
------------------------------
ID: 4330
Name: Automated Resume Job Matching Engine with Bright Data MCP & OpenAI 4o mini
Total Views: 1,398
Created At: 2025-05-23T00:01:02.829Z
Purchase URL: None

üë§ AUTHOR INFORMATION
------------------------------
Name: Ranjan Dailata
Username: ranjancse
Verified: ‚úÖ Yes
Bio: A Professional based out of India specialized in handling AI-powered automations. Contact me at ranjancse@gmail.com 
Links: https://www.linkedin.com/in/ranjan-dailata/

üìù DESCRIPTION
------------------------------
Notice
Community nodes can only be installed on self-hosted instances of n8n.

Who this is for
The Automated Resume Job Matching Engine is an intelligent workflow designed for career platforms, HR tech startups, recruiting firms, and AI developers who want to streamline job-resume matching using real-time data from LinkedIn and job boards.

This workflow is tailored for:

HR Tech Founders** - Building next-gen recruiting products

Recruiters & Talent Sourcers** - Seeking automated candidate-job fit evaluation

Job Boards & Portals** - Enriching user experience with AI-driven job recommendations

Career Coaches & Resume Writers** - Offering personalized job fit analysis

AI Developers** - Automating large-scale matching tasks using LinkedIn and job data

What problem is this workflow solving?
Manually matching a resume to job description is time-consuming, biased, and inefficient. Additionally, accessing live job postings and candidate profiles requires overcoming web scraping limitations.

This workflow solves:

Automated LinkedIn profile and job post data extraction using Bright Data MCP infrastructure

Semantic matching between job requirements and candidate resume using OpenAI 4o mini

Pagination handling for high-volume job data

End-to-end automation from scraping to delivery via webhook and persisting the job matched response to disk

What this workflow does

Bright Data MCP for Job Data Extraction
Uses Bright Data MCP Clients to extract multiple job listings (supports pagination)

Pulls job data from LinkedIn with the pre-defined filtering criteria's

OpenAI 4o mini LLM Matching Engine
Extracts paginated job data from the Bright Data MCP extracted info via the MCP scrape_as_html tool.

Extracts textual job description information via the scraped job information by leveraging the Bright Data MCP scrape_as_html tool.

AI Job Matching node handles the job description and the candidate resume compare to generate match scores with insights

Data Delivery
Sends final match report to a Webhook Notification endpoint

Persistence of AI matched job response to disk 

Pre-conditions

Knowledge of Model Context Protocol (MCP) is highly essential. Please read this blog post - model-context-protocol
You need to have the Bright Data account and do the necessary setup as mentioned in the Setup section below.
You need to have the Google Gemini API Key. Visit Google AI Studio
You need to install the Bright Data MCP Server @brightdata/mcp
You need to install the n8n-nodes-mcp

Setup

Please make sure to setup n8n locally with MCP Servers by navigating to n8n-nodes-mcp
Please make sure to install the Bright Data MCP Server @brightdata/mcp  on your local machine.
Sign up at Bright Data.
Navigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.
Create a Web Unlocker proxy zone called mcp_unlocker on Bright Data control panel.
In n8n, configure the OpenAi account credentials.
In n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.

Make sure to copy the Bright Data API_TOKEN within the Environments textbox above as API_TOKEN=&lt;your-token&gt;.
Update the Set input fields for candidate resume, keywords and other filtering criteria's.
Update the Webhook HTTP Request node with the Webhook endpoint of your choice.
Update the file name and path to persist on disk.

How to customize this workflow to your needs

Target Different Job Boards

Set input fields with the sites like Indeed, ZipRecruiter, or Monster

Customize Matching Criteria
Adjust the prompt inside the AI Job Match node

Include scoring metrics like skills match %, experience relevance, or cultural fit

Automate Scheduling
Use a Cron Node to periodically check for new jobs matching a profile

Set triggers based on webhook or input form submissions

Output Customization
Add Markdown/PDF formatting for report summaries

Extend with Google Sheets export for internal analytics

Enhance Data Security
Mask personal info before sending to external endpoints

üîß NODES USED
------------------------------
‚Ä¢ HTTP Request - Categories: Core Nodes, Development
‚Ä¢ Basic LLM Chain - Categories: AI, Langchain
‚Ä¢ OpenAI Chat Model - Categories: AI, Langchain
‚Ä¢ Structured Output Parser - Categories: AI, Langchain
‚Ä¢ Information Extractor - Categories: AI, Langchain

Total Nodes: 5

üìä RAW DATA (JSON)
------------------------------
{
  "id": 4330,
  "name": "Automated Resume Job Matching Engine with Bright Data MCP & OpenAI 4o mini",
  "totalViews": 1398,
  "purchaseUrl": null,
  "user": {
    "id": 93657,
    "name": "Ranjan Dailata",
    "username": "ranjancse",
    "bio": "A Professional based out of India specialized in handling AI-powered automations. Contact me at ranjancse@gmail.com ",
    "verified": true,
    "links": "[\"https://www.linkedin.com/in/ranjan-dailata/\"]",
    "avatar": "https://gravatar.com/avatar/7b74fe44a7ad32db7c783b972deb5848a4b1f043377bce4039737ed66da8305f?r=pg&d=retro&size=200"
  },
  "description": "\nNotice\nCommunity nodes can only be installed on self-hosted instances of n8n.\n\nWho this is for\nThe Automated Resume Job Matching Engine is an intelligent workflow designed for career platforms, HR tech startups, recruiting firms, and AI developers who want to streamline job-resume matching using real-time data from LinkedIn and job boards.\n\nThis workflow is tailored for:\n\nHR Tech Founders** - Building next-gen recruiting products\n\nRecruiters & Talent Sourcers** - Seeking automated candidate-job fit evaluation\n\nJob Boards & Portals** - Enriching user experience with AI-driven job recommendations\n\nCareer Coaches & Resume Writers** - Offering personalized job fit analysis\n\nAI Developers** - Automating large-scale matching tasks using LinkedIn and job data\n\nWhat problem is this workflow solving?\nManually matching a resume to job description is time-consuming, biased, and inefficient. Additionally, accessing live job postings and candidate profiles requires overcoming web scraping limitations.\n\nThis workflow solves:\n\nAutomated LinkedIn profile and job post data extraction using Bright Data MCP infrastructure\n\nSemantic matching between job requirements and candidate resume using OpenAI 4o mini\n\nPagination handling for high-volume job data\n\nEnd-to-end automation from scraping to delivery via webhook and persisting the job matched response to disk\n\nWhat this workflow does\n\nBright Data MCP for Job Data Extraction\nUses Bright Data MCP Clients to extract multiple job listings (supports pagination)\n\nPulls job data from LinkedIn with the pre-defined filtering criteria's\n\nOpenAI 4o mini LLM Matching Engine\nExtracts paginated job data from the Bright Data MCP extracted info via the MCP scrape_as_html tool.\n\nExtracts textual job description information via the scraped job information by leveraging the Bright Data MCP scrape_as_html tool.\n\nAI Job Matching node handles the job description and the candidate resume compare to generate match scores with insights\n\nData Delivery\nSends final match report to a Webhook Notification endpoint\n\nPersistence of AI matched job response to disk \n\nPre-conditions\n\nKnowledge of Model Context Protocol (MCP) is highly essential. Please read this blog post - model-context-protocol\nYou need to have the Bright Data account and do the necessary setup as mentioned in the Setup section below.\nYou need to have the Google Gemini API Key. Visit Google AI Studio\nYou need to install the Bright Data MCP Server @brightdata/mcp\nYou need to install the n8n-nodes-mcp\n\nSetup\n\nPlease make sure to setup n8n locally with MCP Servers by navigating to n8n-nodes-mcp\nPlease make sure to install the Bright Data MCP Server @brightdata/mcp  on your local machine.\nSign up at Bright Data.\nNavigate to Proxies & Scraping and create a new Web Unlocker zone by selecting Web Unlocker API under Scraping Solutions.\nCreate a Web Unlocker proxy zone called mcp_unlocker on Bright Data control panel.\nIn n8n, configure the OpenAi account credentials.\nIn n8n, configure the credentials to connect with MCP Client (STDIO) account with the Bright Data MCP Server as shown below.\n\nMake sure to copy the Bright Data API_TOKEN within the Environments textbox above as API_TOKEN=&lt;your-token&gt;.\nUpdate the Set input fields for candidate resume, keywords and other filtering criteria's.\nUpdate the Webhook HTTP Request node with the Webhook endpoint of your choice.\nUpdate the file name and path to persist on disk.\n\nHow to customize this workflow to your needs\n\nTarget Different Job Boards\n\nSet input fields with the sites like Indeed, ZipRecruiter, or Monster\n\nCustomize Matching Criteria\nAdjust the prompt inside the AI Job Match node\n\nInclude scoring metrics like skills match %, experience relevance, or cultural fit\n\nAutomate Scheduling\nUse a Cron Node to periodically check for new jobs matching a profile\n\nSet triggers based on webhook or input form submissions\n\nOutput Customization\nAdd Markdown/PDF formatting for report summaries\n\nExtend with Google Sheets export for internal analytics\n\nEnhance Data Security\nMask personal info before sending to external endpoints\n\n",
  "createdAt": "2025-05-23T00:01:02.829Z",
  "nodes": [
    {
      "id": 19,
      "icon": "file:httprequest.svg",
      "name": "n8n-nodes-base.httpRequest",
      "codex": {
        "data": {
          "alias": [
            "API",
            "Request",
            "URL",
            "Build",
            "cURL"
          ],
          "resources": {
            "generic": [
              {
                "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                "icon": "‚òÄÔ∏è",
                "label": "2021: The Year to Automate the New You with n8n"
              },
              {
                "url": "https://n8n.io/blog/why-business-process-automation-with-n8n-can-change-your-daily-life/",
                "icon": "üß¨",
                "label": "Why business process automation with n8n can change your daily life"
              },
              {
                "url": "https://n8n.io/blog/automatically-pulling-and-visualizing-data-with-n8n/",
                "icon": "üìà",
                "label": "Automatically pulling and visualizing data with n8n"
              },
              {
                "url": "https://n8n.io/blog/learn-how-to-automatically-cross-post-your-content-with-n8n/",
                "icon": "‚úçÔ∏è",
                "label": "Learn how to automatically cross-post your content with n8n"
              },
              {
                "url": "https://n8n.io/blog/automatically-adding-expense-receipts-to-google-sheets-with-telegram-mindee-twilio-and-n8n/",
                "icon": "üßæ",
                "label": "Automatically Adding Expense Receipts to Google Sheets with Telegram, Mindee, Twilio, and n8n"
              },
              {
                "url": "https://n8n.io/blog/running-n8n-on-ships-an-interview-with-maranics/",
                "icon": "üõ≥",
                "label": "Running n8n on ships: An interview with Maranics"
              },
              {
                "url": "https://n8n.io/blog/what-are-apis-how-to-use-them-with-no-code/",
                "icon": " ü™¢",
                "label": "What are APIs and how to use them with no code"
              },
              {
                "url": "https://n8n.io/blog/5-tasks-you-can-automate-with-notion-api/",
                "icon": "‚ö°Ô∏è",
                "label": "5 tasks you can automate with the new Notion API "
              },
              {
                "url": "https://n8n.io/blog/world-poetry-day-workflow/",
                "icon": "üìú",
                "label": "Celebrating World Poetry Day with a daily poem in Telegram"
              },
              {
                "url": "https://n8n.io/blog/automate-google-apps-for-productivity/",
                "icon": "üí°",
                "label": "15 Google apps you can combine and automate to increase productivity"
              },
              {
                "url": "https://n8n.io/blog/automate-designs-with-bannerbear-and-n8n/",
                "icon": "üé®",
                "label": "Automate Designs with Bannerbear and n8n"
              },
              {
                "url": "https://n8n.io/blog/how-uproc-scraped-a-multi-page-website-with-a-low-code-workflow/",
                "icon": " üï∏Ô∏è",
                "label": "How uProc scraped a multi-page website with a low-code workflow"
              },
              {
                "url": "https://n8n.io/blog/building-an-expense-tracking-app-in-10-minutes/",
                "icon": "üì±",
                "label": "Building an expense tracking app in 10 minutes"
              },
              {
                "url": "https://n8n.io/blog/5-workflow-automations-for-mattermost-that-we-love-at-n8n/",
                "icon": "ü§ñ",
                "label": "5 workflow automations for Mattermost that we love at n8n"
              },
              {
                "url": "https://n8n.io/blog/how-to-use-the-http-request-node-the-swiss-army-knife-for-workflow-automation/",
                "icon": "üß∞",
                "label": "How to use the HTTP Request Node - The Swiss Army Knife for Workflow Automation"
              },
              {
                "url": "https://n8n.io/blog/learn-how-to-use-webhooks-with-mattermost-slash-commands/",
                "icon": "ü¶Ñ",
                "label": "Learn how to use webhooks with Mattermost slash commands"
              },
              {
                "url": "https://n8n.io/blog/how-a-membership-development-manager-automates-his-work-and-investments/",
                "icon": "üìà",
                "label": "How a Membership Development Manager automates his work and investments"
              },
              {
                "url": "https://n8n.io/blog/a-low-code-bitcoin-ticker-built-with-questdb-and-n8n-io/",
                "icon": "üìà",
                "label": "A low-code bitcoin ticker built with QuestDB and n8n.io"
              },
              {
                "url": "https://n8n.io/blog/how-to-set-up-a-ci-cd-pipeline-with-no-code/",
                "icon": "üé°",
                "label": "How to set up a no-code CI/CD pipeline with GitHub and TravisCI"
              },
              {
                "url": "https://n8n.io/blog/automations-for-activists/",
                "icon": "‚ú®",
                "label": "How Common Knowledge use workflow automation for activism"
              },
              {
                "url": "https://n8n.io/blog/creating-scheduled-text-affirmations-with-n8n/",
                "icon": "ü§ü",
                "label": "Creating scheduled text affirmations with n8n"
              },
              {
                "url": "https://n8n.io/blog/how-goomer-automated-their-operations-with-over-200-n8n-workflows/",
                "icon": "üõµ",
                "label": "How Goomer automated their operations with over 200 n8n workflows"
              },
              {
                "url": "https://n8n.io/blog/aws-workflow-automation/",
                "label": "7 no-code workflow automations for Amazon Web Services"
              }
            ],
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/"
              }
            ]
          },
          "categories": [
            "Development",
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"output\"]",
      "defaults": {
        "name": "HTTP Request",
        "color": "#0004F5"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "HTTP Request",
      "typeVersion": 4,
      "nodeCategories": [
        {
          "id": 5,
          "name": "Development"
        },
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 1123,
      "icon": "fa:link",
      "name": "@n8n/n8n-nodes-langchain.chainLlm",
      "codex": {
        "data": {
          "alias": [
            "LangChain"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Chains",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Basic LLM Chain",
        "color": "#909298"
      },
      "iconData": {
        "icon": "link",
        "type": "icon"
      },
      "displayName": "Basic LLM Chain",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1153,
      "icon": "file:openAiLight.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "OpenAI Chat Model"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "OpenAI Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1179,
      "icon": "fa:code",
      "name": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "codex": {
        "data": {
          "alias": [
            "json",
            "zod"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Structured Output Parser"
      },
      "iconData": {
        "icon": "code",
        "type": "icon"
      },
      "displayName": "Structured Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1273,
      "icon": "fa:project-diagram",
      "name": "@n8n/n8n-nodes-langchain.informationExtractor",
      "codex": {
        "data": {
          "alias": [
            "NER",
            "parse",
            "parsing",
            "JSON",
            "data extraction",
            "structured"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.information-extractor/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Chains",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Information Extractor"
      },
      "iconData": {
        "icon": "project-diagram",
        "type": "icon"
      },
      "displayName": "Information Extractor",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ]
}
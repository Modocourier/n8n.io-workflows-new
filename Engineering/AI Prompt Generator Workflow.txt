================================================================================
WORKFLOW: AI Prompt Generator Workflow
================================================================================

üìã BASIC INFORMATION
------------------------------
ID: 5045
Name: AI Prompt Generator Workflow
Total Views: 86
Created At: 2025-06-19T13:11:05.033Z
Purchase URL: None

üë§ AUTHOR INFORMATION
------------------------------
Name: Anurag Srivastava
Username: anuragmerndev
Verified: ‚ùå No

üìù DESCRIPTION
------------------------------
üß† AI Prompt Generator Workflow ‚Äì n8n Documentation

Who is this for?

This workflow is for AI builders, prompt engineers, developers, marketers, and no-code creators who want to convert rough user input into structured, high-quality prompts for LLMs. It‚Äôs especially useful for tools that rely on precision prompting and want to automate the discovery of intent and constraints.

What problem is this workflow solving? / Use case

Many users struggle to write effective prompts due to vague ideas or unclear formatting needs. This workflow:
Collects structured user input.
Dynamically generates clarifying questions.
Returns a well-formatted AI prompt based on the user's intent and context.

This ensures the generated prompt is useful for downstream AI agents without requiring technical understanding from the end user.

What this workflow does

Start with a branded form UI  
   The user is shown a styled form with questions like:
   What do you want to build?
   What tools can you access?
   What input can be expected?
   What output do you expect?

Analyze and generate relevant follow-up questions  
   The workflow sends the user's answers to Google Gemini (via LangChain) which outputs 1‚Äì3 clarifying questions. These questions are parsed into a dynamic form.

Loop through and collect follow-up answers  
   Each follow-up question is shown in a form one at a time to capture additional context.

Merge all inputs  
   The base intent and follow-up responses are merged into a single context block.

Generate a final AI-ready prompt  
   The prompt generator node formats everything into a clean, six-section structure:
   &lt;constraints&gt;
   &lt;role&gt;
   &lt;inputs&gt;
   &lt;tools&gt;
   &lt;instructions&gt;
   &lt;conclusions&gt;

Display the final result  
   The finished prompt is shown in a clean UI where users can easily copy and reuse it.

Setup

Credentials Required
   Google Gemini (PaLM) API credentials (already integrated as Google Gemini(PaLM) Api account 2).

Form Trigger
   Ensure the On form submission trigger is exposed via a webhook or public endpoint (e.g. using ngrok or deployed server).

Styling
   Custom CSS is included in all form nodes for a beautiful UI. You can modify this to match your branding.

Environment
   This workflow is compatible with self-hosted n8n or n8n.cloud.
   Webhooks must be accessible to users who will fill out the form.

How to customize this workflow to your needs

Change the base questions**  
  Update the BaseQuestions form node to add or remove fields depending on your use case.

Modify Gemini prompts**  
  You can edit the system prompt inside PromptGenerator to change tone, output structure, or AI instructions.

Change prompt formatting**  
  If you use a different AI agent (like GPT, Claude, or Mistral), adjust the section labels and formatting to suit that agent‚Äôs expected input.

Send results elsewhere**  
  Add integration nodes after PromptGenerator, such as:
  Google Docs / Notion (to log prompts)
  Gmail / Slack (to notify your team)
  Zapier / Make (to push to other automation flows)

Skip follow-up questions (optional)**  
  If your base form collects all needed info, you can bypass the RelevantQuestions form section by modifying conditional logic.

Example Output Prompt (Structure)

&lt;role&gt; You are an AI assistant that converts videos into LinkedIn posts with a witty tone. &lt;/role&gt; &lt;inputs&gt; - A short video (max 5 minutes) - Desired tone: witty - Style: both summary and quotes - Audience: general network &lt;/inputs&gt; &lt;tools&gt; You do not have access to APIs or web search. &lt;/tools&gt; &lt;instructions&gt; 1. Parse transcript. 2. Extract insights and quotes. 3. Write an engaging, witty LinkedIn post under 3000 characters. &lt;/instructions&gt; &lt;constraints&gt; Avoid technical jargon. No generic intros. Make it platform-native. &lt;/constraints&gt; &lt;conclusions&gt; Return a LinkedIn-ready post that starts with a hook and ends with hashtags.

üîß NODES USED
------------------------------
‚Ä¢ Basic LLM Chain - Categories: AI, Langchain
‚Ä¢ Auto-fixing Output Parser - Categories: AI, Langchain
‚Ä¢ Structured Output Parser - Categories: AI, Langchain
‚Ä¢ Google Gemini Chat Model - Categories: AI, Langchain

Total Nodes: 4

üìä RAW DATA (JSON)
------------------------------
{
  "id": 5045,
  "name": "AI Prompt Generator Workflow",
  "totalViews": 86,
  "purchaseUrl": null,
  "user": {
    "id": 95597,
    "name": "Anurag Srivastava",
    "username": "anuragmerndev",
    "bio": "",
    "verified": false,
    "links": "[]",
    "avatar": "https://gravatar.com/avatar/03aedd8668b9d6a5da78c0a8cf3a92997feab613eb923199768b3957a351c5dd?r=pg&d=retro&size=200"
  },
  "description": "üß† AI Prompt Generator Workflow ‚Äì n8n Documentation\n\nWho is this for?\n\nThis workflow is for AI builders, prompt engineers, developers, marketers, and no-code creators who want to convert rough user input into structured, high-quality prompts for LLMs. It‚Äôs especially useful for tools that rely on precision prompting and want to automate the discovery of intent and constraints.\n\nWhat problem is this workflow solving? / Use case\n\nMany users struggle to write effective prompts due to vague ideas or unclear formatting needs. This workflow:\nCollects structured user input.\nDynamically generates clarifying questions.\nReturns a well-formatted AI prompt based on the user's intent and context.\n\nThis ensures the generated prompt is useful for downstream AI agents without requiring technical understanding from the end user.\n\nWhat this workflow does\n\nStart with a branded form UI  \n   The user is shown a styled form with questions like:\n   What do you want to build?\n   What tools can you access?\n   What input can be expected?\n   What output do you expect?\n\nAnalyze and generate relevant follow-up questions  \n   The workflow sends the user's answers to Google Gemini (via LangChain) which outputs 1‚Äì3 clarifying questions. These questions are parsed into a dynamic form.\n\nLoop through and collect follow-up answers  \n   Each follow-up question is shown in a form one at a time to capture additional context.\n\nMerge all inputs  \n   The base intent and follow-up responses are merged into a single context block.\n\nGenerate a final AI-ready prompt  \n   The prompt generator node formats everything into a clean, six-section structure:\n   &lt;constraints&gt;\n   &lt;role&gt;\n   &lt;inputs&gt;\n   &lt;tools&gt;\n   &lt;instructions&gt;\n   &lt;conclusions&gt;\n\nDisplay the final result  \n   The finished prompt is shown in a clean UI where users can easily copy and reuse it.\n\nSetup\n\nCredentials Required\n   Google Gemini (PaLM) API credentials (already integrated as Google Gemini(PaLM) Api account 2).\n\nForm Trigger\n   Ensure the On form submission trigger is exposed via a webhook or public endpoint (e.g. using ngrok or deployed server).\n\nStyling\n   Custom CSS is included in all form nodes for a beautiful UI. You can modify this to match your branding.\n\nEnvironment\n   This workflow is compatible with self-hosted n8n or n8n.cloud.\n   Webhooks must be accessible to users who will fill out the form.\n\nHow to customize this workflow to your needs\n\nChange the base questions**  \n  Update the BaseQuestions form node to add or remove fields depending on your use case.\n\nModify Gemini prompts**  \n  You can edit the system prompt inside PromptGenerator to change tone, output structure, or AI instructions.\n\nChange prompt formatting**  \n  If you use a different AI agent (like GPT, Claude, or Mistral), adjust the section labels and formatting to suit that agent‚Äôs expected input.\n\nSend results elsewhere**  \n  Add integration nodes after PromptGenerator, such as:\n  Google Docs / Notion (to log prompts)\n  Gmail / Slack (to notify your team)\n  Zapier / Make (to push to other automation flows)\n\nSkip follow-up questions (optional)**  \n  If your base form collects all needed info, you can bypass the RelevantQuestions form section by modifying conditional logic.\n\nExample Output Prompt (Structure)\n\n&lt;role&gt; You are an AI assistant that converts videos into LinkedIn posts with a witty tone. &lt;/role&gt; &lt;inputs&gt; - A short video (max 5 minutes) - Desired tone: witty - Style: both summary and quotes - Audience: general network &lt;/inputs&gt; &lt;tools&gt; You do not have access to APIs or web search. &lt;/tools&gt; &lt;instructions&gt; 1. Parse transcript. 2. Extract insights and quotes. 3. Write an engaging, witty LinkedIn post under 3000 characters. &lt;/instructions&gt; &lt;constraints&gt; Avoid technical jargon. No generic intros. Make it platform-native. &lt;/constraints&gt; &lt;conclusions&gt; Return a LinkedIn-ready post that starts with a hook and ends with hashtags.",
  "createdAt": "2025-06-19T13:11:05.033Z",
  "nodes": [
    {
      "id": 1123,
      "icon": "fa:link",
      "name": "@n8n/n8n-nodes-langchain.chainLlm",
      "codex": {
        "data": {
          "alias": [
            "LangChain"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Chains",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Basic LLM Chain",
        "color": "#909298"
      },
      "iconData": {
        "icon": "link",
        "type": "icon"
      },
      "displayName": "Basic LLM Chain",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1175,
      "icon": "fa:tools",
      "name": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserautofixing/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Auto-fixing Output Parser"
      },
      "iconData": {
        "icon": "tools",
        "type": "icon"
      },
      "displayName": "Auto-fixing Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1179,
      "icon": "fa:code",
      "name": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "codex": {
        "data": {
          "alias": [
            "json",
            "zod"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Structured Output Parser"
      },
      "iconData": {
        "icon": "code",
        "type": "icon"
      },
      "displayName": "Structured Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1262,
      "icon": "file:google.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Google Gemini Chat Model"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
      },
      "displayName": "Google Gemini Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ]
}
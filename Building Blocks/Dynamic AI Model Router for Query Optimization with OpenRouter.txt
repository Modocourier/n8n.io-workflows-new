================================================================================
WORKFLOW: Dynamic AI Model Router for Query Optimization with OpenRouter
================================================================================

üìã BASIC INFORMATION
------------------------------
ID: 4237
Name: Dynamic AI Model Router for Query Optimization with OpenRouter
Total Views: 3,300
Created At: 2025-05-20T07:40:19.495Z
Purchase URL: None

üë§ AUTHOR INFORMATION
------------------------------
Name: Davide
Username: n3witalia
Verified: ‚úÖ Yes
Bio: Full-stack Web Developer based in Italy specialising in Marketing & AI-powered automations. For business enquiries, send me an email at info@n3w.it or add me on Linkedin.com/in/davideboizza
Links: https://n3w.it

üìù DESCRIPTION
------------------------------
The Agent Decisioner is a dynamic, AI-powered routing system that automatically selects the most appropriate large language model (LLM) to respond to a user's query based on the query‚Äôs content and purpose.

This workflow ensures dynamic, optimized AI responses by intelligently routing queries to the best-suited model.

Advantages

üîÅ Automatic Model Routing:**
  Automatically selects the best model for the job, improving efficiency and relevance of responses.

üéØ Optimized Use of Resources:**
  Avoids overuse of expensive models like GPT-4 by routing simpler queries to lightweight models.

üìö Model-Aware Reasoning:**
  Uses detailed metadata about model capabilities (e.g., reasoning, coding, web search) for intelligent selection.

üì• Modular and Extendable:**
  Easy to integrate with other tools or expand by adding more models or custom decision logic.

üë®‚Äçüíª Ideal for RAG and Multi-Agent Systems:**
  Can serve as the brain behind more complex agent frameworks or Retrieval-Augmented Generation pipelines.

How It Works  

Chat Trigger: The workflow starts when a user sends a message, triggering the Routing Agent.  
Model Selection: The AI Agent analyzes the query and selects the best-suited model from the available options (e.g., Claude 3.7 Sonnet for coding, Perplexity/Sonar for web searches, GPT-4o Mini for reasoning).  
Structured Output: The agent returns a JSON response with the user‚Äôs prompt and the chosen model.  
Execution: The selected model processes the query and generates a response, ensuring optimal performance for the task.  

Set Up Steps  

Configure Nodes:  
   Chat Trigger: Set up the webhook to receive user messages.  
   Routing Agent (AI Agent): Define the system message with model strengths and JSON output rules.  
   OpenRouter Chat Model: Connect to OpenRouter for model access.  
   Structured Output Parser: Ensure it validates the JSON response format (prompt + model).  
   Execution Agent (AI Agent1): Configure it to forward the prompt to the selected model.  

Connect Nodes:  
   Link the Chat Trigger to the Routing Agent.  
   Connect the OpenRouter Chat Model and Output Parser to the Routing Agent.  
   Route the parsed JSON to the Execution Agent, which uses the chosen model via OpenRouter Chat Model1.  

Credentials:  
   Ensure OpenRouter API credentials are correctly set for both chat model nodes.  

Test & Deploy:  
   Activate the workflow and test with sample queries to verify model selection logic.  
   Adjust the routing rules if needed for better accuracy.  

Need help customizing?  
Contact me for consulting and support or add me on Linkedin.

üîß NODES USED
------------------------------
‚Ä¢ AI Agent - Categories: AI, Langchain
‚Ä¢ OpenAI Chat Model - Categories: AI, Langchain
‚Ä¢ Auto-fixing Output Parser - Categories: AI, Langchain
‚Ä¢ Structured Output Parser - Categories: AI, Langchain
‚Ä¢ OpenRouter Chat Model - Categories: AI, Langchain

Total Nodes: 5

üìä RAW DATA (JSON)
------------------------------
{
  "id": 4237,
  "name": "Dynamic AI Model Router for Query Optimization with OpenRouter",
  "totalViews": 3300,
  "purchaseUrl": null,
  "user": {
    "id": 92207,
    "name": "Davide",
    "username": "n3witalia",
    "bio": "Full-stack Web Developer based in Italy specialising in Marketing & AI-powered automations. For business enquiries, send me an email at info@n3w.it or add me on Linkedin.com/in/davideboizza",
    "verified": true,
    "links": "[\"https://n3w.it\"]",
    "avatar": "https://gravatar.com/avatar/d41b8a0aa81139243509c58870f5b4be292824a507ab57d10ed066d8628ed8da?r=pg&d=retro&size=200"
  },
  "description": "The Agent Decisioner is a dynamic, AI-powered routing system that automatically selects the most appropriate large language model (LLM) to respond to a user's query based on the query‚Äôs content and purpose.\n\nThis workflow ensures dynamic, optimized AI responses by intelligently routing queries to the best-suited model.\n\nAdvantages\n\nüîÅ Automatic Model Routing:**\n  Automatically selects the best model for the job, improving efficiency and relevance of responses.\n\nüéØ Optimized Use of Resources:**\n  Avoids overuse of expensive models like GPT-4 by routing simpler queries to lightweight models.\n\nüìö Model-Aware Reasoning:**\n  Uses detailed metadata about model capabilities (e.g., reasoning, coding, web search) for intelligent selection.\n\nüì• Modular and Extendable:**\n  Easy to integrate with other tools or expand by adding more models or custom decision logic.\n\nüë®‚Äçüíª Ideal for RAG and Multi-Agent Systems:**\n  Can serve as the brain behind more complex agent frameworks or Retrieval-Augmented Generation pipelines.\n\nHow It Works  \n\nChat Trigger: The workflow starts when a user sends a message, triggering the Routing Agent.  \nModel Selection: The AI Agent analyzes the query and selects the best-suited model from the available options (e.g., Claude 3.7 Sonnet for coding, Perplexity/Sonar for web searches, GPT-4o Mini for reasoning).  \nStructured Output: The agent returns a JSON response with the user‚Äôs prompt and the chosen model.  \nExecution: The selected model processes the query and generates a response, ensuring optimal performance for the task.  \n\nSet Up Steps  \n\nConfigure Nodes:  \n   Chat Trigger: Set up the webhook to receive user messages.  \n   Routing Agent (AI Agent): Define the system message with model strengths and JSON output rules.  \n   OpenRouter Chat Model: Connect to OpenRouter for model access.  \n   Structured Output Parser: Ensure it validates the JSON response format (prompt + model).  \n   Execution Agent (AI Agent1): Configure it to forward the prompt to the selected model.  \n\nConnect Nodes:  \n   Link the Chat Trigger to the Routing Agent.  \n   Connect the OpenRouter Chat Model and Output Parser to the Routing Agent.  \n   Route the parsed JSON to the Execution Agent, which uses the chosen model via OpenRouter Chat Model1.  \n\nCredentials:  \n   Ensure OpenRouter API credentials are correctly set for both chat model nodes.  \n\nTest & Deploy:  \n   Activate the workflow and test with sample queries to verify model selection logic.  \n   Adjust the routing rules if needed for better accuracy.  \n\nNeed help customizing?  \nContact me for consulting and support or add me on Linkedin. ",
  "createdAt": "2025-05-20T07:40:19.495Z",
  "nodes": [
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "AI Agent",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1153,
      "icon": "file:openAiLight.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "OpenAI Chat Model"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "OpenAI Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1175,
      "icon": "fa:tools",
      "name": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserautofixing/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Auto-fixing Output Parser"
      },
      "iconData": {
        "icon": "tools",
        "type": "icon"
      },
      "displayName": "Auto-fixing Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1179,
      "icon": "fa:code",
      "name": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "codex": {
        "data": {
          "alias": [
            "json",
            "zod"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Structured Output Parser"
      },
      "iconData": {
        "icon": "code",
        "type": "icon"
      },
      "displayName": "Structured Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1281,
      "icon": "file:openrouter.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenrouter/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "OpenRouter Chat Model"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjOTRBM0I4IiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHdpZHRoPSI0MCIgaGVpZ2h0PSI0MCIgdmlld0JveD0iMCAwIDI0IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjx0aXRsZT5PcGVuUm91dGVyPC90aXRsZT48cGF0aCBkPSJNMTYuODA0IDEuOTU3bDcuMjIgNC4xMDV2LjA4N0wxNi43MyAxMC4yMWwuMDE3LTIuMTE3LS44MjEtLjAzYy0xLjA1OS0uMDI4LTEuNjExLjAwMi0yLjI2OC4xMS0xLjA2NC4xNzUtMi4wMzguNTc3LTMuMTQ3IDEuMzUyTDguMzQ1IDExLjAzYy0uMjg0LjE5NS0uNDk1LjMzNi0uNjguNDU1bC0uNTE1LjMyMi0uMzk3LjIzNC4zODUuMjMuNTMuMzM4Yy40NzYuMzE0IDEuMTcuNzk2IDIuNzAxIDEuODY2IDEuMTEuNzc1IDIuMDgzIDEuMTc3IDMuMTQ3IDEuMzUybC4zLjA0NWMuNjk0LjA5MSAxLjM3NS4wOTQgMi44MjUuMDMzbC4wMjItMi4xNTkgNy4yMiA0LjEwNXYuMDg3TDE2LjU4OSAyMmwuMDE0LTEuODYyLS42MzUuMDIyYy0xLjM4Ni4wNDItMi4xMzcuMDAyLTMuMTM4LS4xNjItMS42OTQtLjI4LTMuMjYtLjkyNi00Ljg4MS0yLjA1OWwtMi4xNTgtMS41YTIxLjk5NyAyMS45OTcgMCAwMC0uNzU1LS40OThsLS40NjctLjI4YTU1LjkyNyA1NS45MjcgMCAwMC0uNzYtLjQzQzIuOTA4IDE0LjczLjU2MyAxNC4xMTYgMCAxNC4xMTZWOS44ODhsLjE0LjAwNGMuNTY0LS4wMDcgMi45MS0uNjIyIDMuODA5LTEuMTI0bDEuMDE2LS41OC40MzgtLjI3NGMuNDI4LS4yOCAxLjA3Mi0uNzI2IDIuNjg2LTEuODUzIDEuNjIxLTEuMTMzIDMuMTg2LTEuNzggNC44ODEtMi4wNTkgMS4xNTItLjE5IDEuOTc0LS4yMTMgMy44MTQtLjEzOGwuMDItMS45MDd6Ij48L3BhdGg+PC9zdmc+Cg=="
      },
      "displayName": "OpenRouter Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ]
}
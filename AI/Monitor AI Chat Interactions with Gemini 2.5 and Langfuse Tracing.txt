================================================================================
WORKFLOW: Monitor AI Chat Interactions with Gemini 2.5 and Langfuse Tracing
================================================================================

üìã BASIC INFORMATION
------------------------------
ID: 4972
Name: Monitor AI Chat Interactions with Gemini 2.5 and Langfuse Tracing
Total Views: 48
Created At: 2025-06-16T14:01:56.103Z
Purchase URL: None

üë§ AUTHOR INFORMATION
------------------------------
Name: Eduardo Hales
Username: ehales
Verified: ‚ùå No
Bio: Full Stack Developer with 8+ years building web applications, now focused on AI engineering and cybersecurity. I integrate LLMs into production systems, conduct security audits, and help teams build safer, smarter software. Particularly interested in making AI applications both powerful and secure.
Links: 

üìù DESCRIPTION
------------------------------
This workflow contains community nodes that are only compatible with the self-hosted version of n8n.

How it works

This workflow is a simple AI Agent that connects to Langfuse so send tracing data to help monitor LLM interactions.

The main idea is to create a custom LLM model that allows the configuration of callbacks, which are used by langchain to connect applications such Langfuse.

This is achieves by using the "langchain code" node:
Connects a LLM model sub-node to obtain the model variables (model name, temp and provider) - Creates a generic langchain initChatModel with the model parameters.
Return the LLM to be used by the AI Agent node.

üìã Prerequisites
Langfuse instance (cloud or self-hosted) with API credentials
LLM API key (Gemini, OpenAI, Anthropic, etc.)
n8n &gt;= 1.98.0 (required for LangChain code node support in AI Agent)

‚öôÔ∏è Setup

Add these to your n8n instance:
Langfuse configuration
LANGFUSE_SECRET_KEY=your_secret_key
LANGFUSE_PUBLIC_KEY=your_public_key
LANGFUSE_BASEURL=https://cloud.langfuse.com  # or your self-hosted URL

LLM API key (example for Gemini)
GOOGLE_API_KEY=your_api_key

Alternative: Configure these directly in the LangChain code node if you prefer not to use environment variables

Import the workflow JSON

Connect your preferred LLM model node

Send a test message to verify tracing appears in Langfuse

üîß NODES USED
------------------------------
‚Ä¢ AI Agent - Categories: AI, Langchain
‚Ä¢ LangChain Code - Categories: AI, Langchain
‚Ä¢ Simple Memory - Categories: AI, Langchain
‚Ä¢ Google Gemini Chat Model - Categories: AI, Langchain

Total Nodes: 4

üìä RAW DATA (JSON)
------------------------------
{
  "id": 4972,
  "name": "Monitor AI Chat Interactions with Gemini 2.5 and Langfuse Tracing",
  "totalViews": 48,
  "purchaseUrl": null,
  "user": {
    "id": 95493,
    "name": "Eduardo Hales",
    "username": "ehales",
    "bio": "Full Stack Developer with 8+ years building web applications, now focused on AI engineering and cybersecurity. I integrate LLMs into production systems, conduct security audits, and help teams build safer, smarter software. Particularly interested in making AI applications both powerful and secure.",
    "verified": false,
    "links": "[\"\"]",
    "avatar": "https://gravatar.com/avatar/e66357d2e395080b10b4bce9323106ba84f3e31da6a305badee6159c7cc77127?r=pg&d=retro&size=200"
  },
  "description": "This workflow contains community nodes that are only compatible with the self-hosted version of n8n.\n\nHow it works\n\nThis workflow is a simple AI Agent that connects to Langfuse so send tracing data to help monitor LLM interactions.\n\nThe main idea is to create a custom LLM model that allows the configuration of callbacks, which are used by langchain to connect applications such Langfuse.\n\nThis is achieves by using the \"langchain code\" node:\nConnects a LLM model sub-node to obtain the model variables (model name, temp and provider) - Creates a generic langchain initChatModel with the model parameters.\nReturn the LLM to be used by the AI Agent node.\n\nüìã Prerequisites\nLangfuse instance (cloud or self-hosted) with API credentials\nLLM API key (Gemini, OpenAI, Anthropic, etc.)\nn8n &gt;= 1.98.0 (required for LangChain code node support in AI Agent)\n\n‚öôÔ∏è Setup\n\nAdd these to your n8n instance:\nLangfuse configuration\nLANGFUSE_SECRET_KEY=your_secret_key\nLANGFUSE_PUBLIC_KEY=your_public_key\nLANGFUSE_BASEURL=https://cloud.langfuse.com  # or your self-hosted URL\n\nLLM API key (example for Gemini)\nGOOGLE_API_KEY=your_api_key\n\nAlternative: Configure these directly in the LangChain code node if you prefer not to use environment variables\n\nImport the workflow JSON\n\nConnect your preferred LLM model node\n\nSend a test message to verify tracing appears in Langfuse\n",
  "createdAt": "2025-06-16T14:01:56.103Z",
  "nodes": [
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "AI Agent",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1127,
      "icon": "fa:code",
      "name": "@n8n/n8n-nodes-langchain.code",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Miscellaneous"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "LangChain Code"
      },
      "iconData": {
        "icon": "code",
        "type": "icon"
      },
      "displayName": "LangChain Code",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1163,
      "icon": "fa:database",
      "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Memory"
            ],
            "Memory": [
              "For beginners"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Simple Memory"
      },
      "iconData": {
        "icon": "database",
        "type": "icon"
      },
      "displayName": "Simple Memory",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1262,
      "icon": "file:google.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Google Gemini Chat Model"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
      },
      "displayName": "Google Gemini Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ]
}
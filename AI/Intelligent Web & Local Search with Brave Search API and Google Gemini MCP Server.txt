================================================================================
WORKFLOW: Intelligent Web & Local Search with Brave Search API and Google Gemini MCP Server
================================================================================

üìã BASIC INFORMATION
------------------------------
ID: 4559
Name: Intelligent Web & Local Search with Brave Search API and Google Gemini MCP Server
Total Views: 341
Created At: 2025-06-01T12:10:43.912Z
Purchase URL: None

üë§ AUTHOR INFORMATION
------------------------------
Name: Jez
Username: jez
Verified: ‚úÖ Yes
Bio: I'm passionate about combining traditional web development with AI and automation to create impactful online solutions. As Founder & CEO of Jezweb, an award-winning Newcastle, Australia agency, I lead a 30+ person team delivering high-quality web design, development, and hosting services to over 3000 clients.
Links: https://www.jezweb.com.au

üìù DESCRIPTION
------------------------------
Summary
This n8n workflow implements an AI-powered agent that intelligently uses the Brave Search API (via an external MCP service like Smithery) to perform both web and local searches. It understands natural language queries, selects the appropriate search tool, and exposes this enhanced capability as a single, callable MCP tool.

Key Features
ü§ñ Intelligent Tool Selection: AI agent decides between Brave's web search and local search tools based on user query context.
üåê MCP Microservice: Exposes complex search logic as a single, easy-to-integrate MCP tool (call_brave_search_agent).
üß† Powered by Google Gemini: Utilizes the gemini-2.5-flash-preview-05-20 LLM for advanced reasoning.
üó£Ô∏è Conversational Memory: Remembers context within a single execution flow.
üìù Customizable System Prompt: Tailor the AI's behavior and responses.
üß© Modular Design: Connects to external Brave Search MCP tools (e.g., from Smithery).

Benefits
üîå Simplified Integration: Easily add advanced, AI-driven search capabilities to other applications or agent systems.
üí∏ Reduced Client-Side LLM Costs: Offloads complex prompting and tool orchestration to n8n, minimizing token usage for client-side LLMs.
üîß Centralized Logic: Manage and update search strategies and AI behavior in one place.
üöÄ Extensible: Can be adapted to use other search tools or incorporate more complex decision-making.

Nodes Used
@n8n/n8n-nodes-langchain.mcpTrigger (MCP Server Trigger)
@n8n/n8n-nodes-langchain.toolWorkflow
@n8n/n8n-nodes-langchain.agent (AI Agent)
@n8n/n8n-nodes-langchain.lmChatGoogleGemini (Google Gemini Chat Model)
n8n-nodes-mcp.mcpClientTool (MCP Client Tool - for Brave Search)
@n8n/n8n-nodes-langchain.memoryBufferWindow (Simple Memory)
n8n-nodes-base.executeWorkflowTrigger (Workflow Start - for direct execution/testing)

Prerequisites
An active n8n instance (v1.22.5+ recommended).
A Google AI API key for using the Gemini LLM.
Access to an external MCP service that provides Brave Search tools (e.g., a Smithery account configured with their Brave Search MCP). This includes the MCP endpoint URL and any necessary authentication (like an API key for Smithery).

Setup Instructions
Import Workflow: Download the Brave_Search_Smithery_AI_Agent_MCP_Server.json file and import it into your n8n instance.
Configure LLM Credential:
    Locate the 'Google Gemini Chat Model' node.
    Select or create an n8n credential for "Google Palm API" (used for Gemini), providing your Google AI API key.
Configure Brave Search MCP Credential:
    Locate the 'brave_web_search' and 'brave_local_search' (MCP Client) nodes.
    Create a new n8n credential of type "MCP Client HTTP API".
        Name: e.g., Smithery Brave Search Access
        Base URL: Enter the URL of your Brave Search MCP endpoint from your provider (e.g., https://server.smithery.ai/@YOUR_PROFILE/brave-search/mcp).
        Authentication: If your MCP provider requires an API key, select "Header Auth". Add a header with the name (e.g., X-API-Key) and value provided by your MCP service.
    Assign this newly created credential to both the 'brave_web_search' and 'brave_local_search' nodes.
Note MCP Trigger Path:
    Open the 'Brave Search MCP Server Trigger' node.
    Copy its unique 'Path' (e.g., /cc8cc827-3e72-4029-8a9d-76519d1c136d). You will combine this with your n8n instance's base URL to get the full endpoint URL for clients.

How to Use
This workflow exposes an MCP tool named call_brave_search_agent. External clients can call this tool via the URL derived from the 'Brave Search MCP Server Trigger'.

Example Client MCP Configuration (e.g., for Roo Code):
"n8n-brave-search-agent": {
  "url": "https://YOUR_N8N_INSTANCE/mcp/cc8cc827-3e72-4029-8a9d-76519d1c136d/sse",
  "alwaysAllow": [
    "call_brave_search_agent"
  ]
}
Replace YOUR_N8N_INSTANCE with your n8n's public URL and ensure the path matches your trigger node.

Example Request:
Send a POST request to the trigger URL with a JSON body:
{
  "input": { "query": "best coffee shops in London" }
}



The agent will stream its response, including the summarized search results.

Customization
AI Behavior:* Modify the System Prompt within the *'Brave Search AI Agent'** node to fine-tune its decision-making, response style, or how it uses the search tools.
LLM Choice:* Replace the *'Google Gemini Chat Model'** node with any other compatible LLM node supported by n8n.
Search Tools:** Adapt the workflow to use different or additional search tools by modifying the MCP Client nodes and updating the AI Agent's system prompt and tool definitions.

Further Information
GitHub Repository: https://github.com/jezweb/n8n
The workflow includes extensive sticky notes for in-canvas documentation.

Author
Jeremy Dawes (Jezweb)

üîß NODES USED
------------------------------
‚Ä¢ AI Agent - Categories: AI, Langchain
‚Ä¢ Simple Memory - Categories: AI, Langchain
‚Ä¢ Call n8n Workflow Tool - Categories: AI, Langchain
‚Ä¢ Google Gemini Chat Model - Categories: AI, Langchain

Total Nodes: 4

üìä RAW DATA (JSON)
------------------------------
{
  "id": 4559,
  "name": "Intelligent Web & Local Search with Brave Search API and Google Gemini MCP Server",
  "totalViews": 341,
  "purchaseUrl": null,
  "user": {
    "id": 95044,
    "name": "Jez",
    "username": "jez",
    "bio": "I'm passionate about combining traditional web development with AI and automation to create impactful online solutions. As Founder & CEO of Jezweb, an award-winning Newcastle, Australia agency, I lead a 30+ person team delivering high-quality web design, development, and hosting services to over 3000 clients.",
    "verified": true,
    "links": "[\"https://www.jezweb.com.au\"]",
    "avatar": "https://gravatar.com/avatar/5f6cbb73f1a61b0bea48b1fac47a94e693ca6f6bc2359eff9c7e68159698efc6?r=pg&d=retro&size=200"
  },
  "description": "Summary\nThis n8n workflow implements an AI-powered agent that intelligently uses the Brave Search API (via an external MCP service like Smithery) to perform both web and local searches. It understands natural language queries, selects the appropriate search tool, and exposes this enhanced capability as a single, callable MCP tool.\n\nKey Features\nü§ñ Intelligent Tool Selection: AI agent decides between Brave's web search and local search tools based on user query context.\nüåê MCP Microservice: Exposes complex search logic as a single, easy-to-integrate MCP tool (call_brave_search_agent).\nüß† Powered by Google Gemini: Utilizes the gemini-2.5-flash-preview-05-20 LLM for advanced reasoning.\nüó£Ô∏è Conversational Memory: Remembers context within a single execution flow.\nüìù Customizable System Prompt: Tailor the AI's behavior and responses.\nüß© Modular Design: Connects to external Brave Search MCP tools (e.g., from Smithery).\n\nBenefits\nüîå Simplified Integration: Easily add advanced, AI-driven search capabilities to other applications or agent systems.\nüí∏ Reduced Client-Side LLM Costs: Offloads complex prompting and tool orchestration to n8n, minimizing token usage for client-side LLMs.\nüîß Centralized Logic: Manage and update search strategies and AI behavior in one place.\nüöÄ Extensible: Can be adapted to use other search tools or incorporate more complex decision-making.\n\nNodes Used\n@n8n/n8n-nodes-langchain.mcpTrigger (MCP Server Trigger)\n@n8n/n8n-nodes-langchain.toolWorkflow\n@n8n/n8n-nodes-langchain.agent (AI Agent)\n@n8n/n8n-nodes-langchain.lmChatGoogleGemini (Google Gemini Chat Model)\nn8n-nodes-mcp.mcpClientTool (MCP Client Tool - for Brave Search)\n@n8n/n8n-nodes-langchain.memoryBufferWindow (Simple Memory)\nn8n-nodes-base.executeWorkflowTrigger (Workflow Start - for direct execution/testing)\n\nPrerequisites\nAn active n8n instance (v1.22.5+ recommended).\nA Google AI API key for using the Gemini LLM.\nAccess to an external MCP service that provides Brave Search tools (e.g., a Smithery account configured with their Brave Search MCP). This includes the MCP endpoint URL and any necessary authentication (like an API key for Smithery).\n\nSetup Instructions\nImport Workflow: Download the Brave_Search_Smithery_AI_Agent_MCP_Server.json file and import it into your n8n instance.\nConfigure LLM Credential:\n    Locate the 'Google Gemini Chat Model' node.\n    Select or create an n8n credential for \"Google Palm API\" (used for Gemini), providing your Google AI API key.\nConfigure Brave Search MCP Credential:\n    Locate the 'brave_web_search' and 'brave_local_search' (MCP Client) nodes.\n    Create a new n8n credential of type \"MCP Client HTTP API\".\n        Name: e.g., Smithery Brave Search Access\n        Base URL: Enter the URL of your Brave Search MCP endpoint from your provider (e.g., https://server.smithery.ai/@YOUR_PROFILE/brave-search/mcp).\n        Authentication: If your MCP provider requires an API key, select \"Header Auth\". Add a header with the name (e.g., X-API-Key) and value provided by your MCP service.\n    Assign this newly created credential to both the 'brave_web_search' and 'brave_local_search' nodes.\nNote MCP Trigger Path:\n    Open the 'Brave Search MCP Server Trigger' node.\n    Copy its unique 'Path' (e.g., /cc8cc827-3e72-4029-8a9d-76519d1c136d). You will combine this with your n8n instance's base URL to get the full endpoint URL for clients.\n\nHow to Use\nThis workflow exposes an MCP tool named call_brave_search_agent. External clients can call this tool via the URL derived from the 'Brave Search MCP Server Trigger'.\n\nExample Client MCP Configuration (e.g., for Roo Code):\n\"n8n-brave-search-agent\": {\n  \"url\": \"https://YOUR_N8N_INSTANCE/mcp/cc8cc827-3e72-4029-8a9d-76519d1c136d/sse\",\n  \"alwaysAllow\": [\n    \"call_brave_search_agent\"\n  ]\n}\nReplace YOUR_N8N_INSTANCE with your n8n's public URL and ensure the path matches your trigger node.\n\nExample Request:\nSend a POST request to the trigger URL with a JSON body:\n{\n  \"input\": { \"query\": \"best coffee shops in London\" }\n}\n\n\n\nThe agent will stream its response, including the summarized search results.\n\nCustomization\nAI Behavior:* Modify the System Prompt within the *'Brave Search AI Agent'** node to fine-tune its decision-making, response style, or how it uses the search tools.\nLLM Choice:* Replace the *'Google Gemini Chat Model'** node with any other compatible LLM node supported by n8n.\nSearch Tools:** Adapt the workflow to use different or additional search tools by modifying the MCP Client nodes and updating the AI Agent's system prompt and tool definitions.\n\nFurther Information\nGitHub Repository: https://github.com/jezweb/n8n\nThe workflow includes extensive sticky notes for in-canvas documentation.\n\nAuthor\nJeremy Dawes (Jezweb)",
  "createdAt": "2025-06-01T12:10:43.912Z",
  "nodes": [
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "AI Agent",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1163,
      "icon": "fa:database",
      "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Memory"
            ],
            "Memory": [
              "For beginners"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Simple Memory"
      },
      "iconData": {
        "icon": "database",
        "type": "icon"
      },
      "displayName": "Simple Memory",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1205,
      "icon": "fa:network-wired",
      "name": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolworkflow/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Tools"
            ],
            "Tools": [
              "Recommended Tools"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Call n8n Workflow Tool"
      },
      "iconData": {
        "icon": "network-wired",
        "type": "icon"
      },
      "displayName": "Call n8n Workflow Tool",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1262,
      "icon": "file:google.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Google Gemini Chat Model"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
      },
      "displayName": "Google Gemini Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ]
}